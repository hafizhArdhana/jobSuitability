{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8996164d-69e0-4b10-ae1a-4c16a8b20d70",
   "metadata": {},
   "source": [
    "## IMPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229d8c78-e761-4498-b0e8-5dbfe22bb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import pdfplumber\n",
    "from docx import Document\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f552998b-bb07-4789-b7b5-d389ddc4dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GOOGLE_API_KEY ditemukan.\n",
      "‚úÖ Google Generative AI configured.\n"
     ]
    }
   ],
   "source": [
    "# Tambahkan API Key\n",
    "API_KEY = 'AIzaSyBtNixliDZyFJS_xmp1i1jp5AfCQyHVozs'\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"‚ùå GOOGLE_API_KEY environment variable not set. Please set it in your terminal before starting Jupyter.\")\n",
    "else:\n",
    "    print(\"‚úÖ GOOGLE_API_KEY ditemukan.\")\n",
    "\n",
    "# Konfigurasi Gemini API\n",
    "genai.configure(api_key=API_KEY)\n",
    "print(\"‚úÖ Google Generative AI configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1035182-82b7-4607-a3ad-5b860a343c05",
   "metadata": {},
   "source": [
    "## Path!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae94d844-46a2-48b4-abfd-87feb0a203df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = 'D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\Data CV' # <- Buat path inputan CV format PDF / docx\n",
    "\n",
    "# Buat folder untuk menyimpan hasil JSON\n",
    "output_directory = 'D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data' # Folder tempat hasil akan disimpan (relatif terhadap lokasi notebook)\n",
    "#os.makedirs(output_directory, exist_ok=True) # Buat folder kalau belum ada\n",
    "\n",
    "# Ganti string di bawah ini dengan path folder yang berisi file-file JSON hasil ekstraksi.\n",
    "json_folder_path = \"extracted_cv_data\" # Contoh: './extracted_cv_data' atau 'E:/Project/Capstone/Data_CV_Extracted'\n",
    "\n",
    "# --- Path data pekerjaan dari CSV ---\n",
    "job_csv_path = \"D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\jobRequirement.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f2ad1-4d18-4091-8e68-6c2277e3e813",
   "metadata": {},
   "source": [
    "# Ekstraksi CV dari PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12310ddd-f8f2-428d-b12f-83b8062e58bb",
   "metadata": {},
   "source": [
    "## Fungsi Ekstraksi Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f59e07f0-34c9-45ed-9d33-5afe48b96e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fungsi ekstraksi teks siap.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Fungsi Ekstraksi Teks ---\n",
    "\n",
    "# üìå Fungsi untuk Ekstrak Teks dari PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Ekstrak teks dari file PDF menggunakan pdfplumber.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Handle potential None results from extract_text()\n",
    "            text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "        return text if text else \"üìÑ (PDF ini kosong atau tidak dapat diekstrak teksnya)\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"‚ùå Error: File PDF tidak ditemukan di {pdf_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error membaca PDF {pdf_path}: {e}\"\n",
    "\n",
    "# üìå Fungsi untuk Ekstrak Teks dari DOCX\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"Ekstrak teks dari file DOCX menggunakan python-docx.\"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        return text if text else \"üìÑ (DOCX ini kosong atau tidak dapat diekstrak teksnya)\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"‚ùå Error: File DOCX tidak ditemukan di {docx_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error membaca DOCX {docx_path}: {e}\"\n",
    "\n",
    "# üìå Fungsi untuk Deteksi Format File & Ekstraksi Teks\n",
    "def extract_text(file_path):\n",
    "    \"\"\"Deteksi format file (PDF/DOCX) dan ekstraksi teks.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return f\"‚ùå Error: File tidak ditemukan di {file_path}\"\n",
    "\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        return \"‚ùå Format file tidak didukung! Gunakan PDF atau DOCX.\"\n",
    "\n",
    "print(\"‚úÖ Fungsi ekstraksi teks siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9a4e8f-726a-46f7-a561-05aa5175898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fungsi ekstraksi teks siap (menerima prompt string sebagai argumen - pakai variabel 'prompt_template').\n"
     ]
    }
   ],
   "source": [
    "# üìå Fungsi untuk Ekstraksi NER (Menggunakan Gemini via genai)\n",
    "# Fungsi ini menerima teks CV dan string prompt (prompt_template) sebagai argumen\n",
    "def extract_ner_from_cv(text, prompt_template): # <-- Di sini fungsi nerima prompt string dari luar\n",
    "    \"\"\"Mengirim teks CV dan prompt ke model Gemini untuk ekstraksi NER dan output JSON.\"\"\"\n",
    "    # Skip processing if text extraction failed or resulted in empty/error text\n",
    "    if not text or text.startswith(\"‚ùå Error\") or text.startswith(\"üìÑ (\"):\n",
    "        print(\"‚ö†Ô∏è Skipping NER extraction due to empty or problematic text.\")\n",
    "        return {\"error\": \"No valid text provided for processing.\"}\n",
    "\n",
    "    # Pastikan prompt_template punya placeholder {text}. Ini penting!\n",
    "    if \"{text}\" not in prompt_template:\n",
    "         # Bisa ganti ini jadi raise ValueError kalau mau error fatal kalo {text} ga ada\n",
    "         print(\"‚ùå Warning: Prompt template does not contain '{text}' placeholder. CV text will not be included!\")\n",
    "\n",
    "    final_prompt = prompt_template.format(text=text)\n",
    "\n",
    "    # Use the configured generative model (e.g., gemini-1.5-flash-latest)\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash-latest\") # Model tetap sama\n",
    "        print(\"‚è≥ Calling Generative Model...\")\n",
    "        response = model.generate_content(final_prompt) # Menggunakan prompt yang sudah diformat\n",
    "\n",
    "        response_text = response.text.strip()\n",
    "\n",
    "        # Find the JSON block explicitly marked by ```json and ```\n",
    "        json_start = response_text.find(\"```json\")\n",
    "        json_end = response_text.find(\"```\", json_start + 7) # Search for closing ``` after the opening one\n",
    "\n",
    "        if json_start != -1 and json_end != -1:\n",
    "            json_block = response_text[json_start + 7:json_end].strip()\n",
    "            print(\"‚úÖ Found potential JSON block. Attempting to parse...\")\n",
    "            return json.loads(json_block)\n",
    "        else:\n",
    "            print(\"\\n‚ùå Error: Could not find valid JSON block (```json...```) in model response.\")\n",
    "            print(\"Raw response received was:\", response_text)\n",
    "            return {\"error\": \"Invalid JSON block format in response\", \"raw_response\": response_text}\n",
    "\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\n‚ùå Error parsing JSON from model response: {e}\")\n",
    "        print(\"Raw response text that caused error:\", response_text)\n",
    "        return {\"error\": \"Invalid JSON structure from model\", \"raw_response\": response_text}\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An API or unexpected error occurred: {e}\")\n",
    "        return {\"error\": f\"API error: {e}\", \"raw_response\": response.text if 'response' in locals() else \"No response object\"}\n",
    "\n",
    "print(\"‚úÖ Fungsi ekstraksi teks siap (menerima prompt string sebagai argumen - pakai variabel 'prompt_template').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4679b46-9f82-4ee2-bb5a-b1cc985cf26d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Mencari file PDF dan DOCX di folder: D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\Data CV\n",
      "‚úÖ Ditemukan 9 file PDF/DOCX.\n",
      "üìÇ Akan memproses 9 file...\n",
      "üíæ Hasil akan disimpan di folder: D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\n",
      "\n",
      "--- Memproses file: CV Aqiela Putriana Shabira.pdf ---\n",
      "üìå Ekstraksi teks dari CV Aqiela Putriana Shabira.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "AQIELA PUTRIANA SHABIRA\n",
      "Bandung, Jawa Barat | No. Telepon : 081367788798\n",
      "Email: aqielanara@student.telkomuniversity.ac.id\n",
      "LinkedIn : www.linkedin.com/in/aqiela-putriana-shabira-17b709249\n",
      "Saya adalah mahasiswi jurusan Data Sains, Fakultas Informatika, Universitas Telkom angkatan 2022. Sebagai\n",
      "mahasiswi yang aktif di bidang IT, saya terus mengembangkan diri melalui berbagai kegiatan akademik dan non-\n",
      "akademik, baik di dalam maupun di luar universitas. Saya memiliki kemampuan manajemen waktu yang b...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV Aqiela Putriana Shabira_extraction_result.json`\n",
      "\n",
      "--- Memproses file: CV_ Hanum Fadiannur.pdf ---\n",
      "üìå Ekstraksi teks dari CV_ Hanum Fadiannur.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "HANUM FADIANNUR\n",
      "082181757523 | hanumfadiannur29@gmail.com | https://www.linkedin.com/in/hanum-fadiannur/\n",
      "Saya memiliki pengalaman dalam bidang pengajaran, public speaking, serta menunjukkan\n",
      "sikap disiplin dan tanggung jawab yang tinggi. Sebagai asisten dosen pada mata kuliah\n",
      "Struktur Data, saya berperan dalam membantu mahasiswa memahami materi secara lebih\n",
      "mendalam. Saya tertarik pada bidang data analyst, machine learning, dan software engineer,\n",
      "serta sedang mempelajari Laravel dan Tableau.\n",
      "Pend...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV_ Hanum Fadiannur_extraction_result.json`\n",
      "\n",
      "--- Memproses file: CV_Dito Adistya Wirawan.pdf ---\n",
      "üìå Ekstraksi teks dari CV_Dito Adistya Wirawan.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "DITO ADISTYA WIRAWAN\n",
      "081903564605 | ditoadistya@student.telkomuniversity.ac.id | https://www.linkedin.com/in/ditoadistya/ |\n",
      "Bandung\n",
      "Mahasiswa S1 Sains Data dengan minat pada analisis data dan machine learning. Menguasai Python, R, SQL, dan visualisasi data.\n",
      "Berpengalaman dalam pemrosesan data besar dan pemodelan prediktif untuk mendukung keputusan berbasis data.\n",
      "PENDIDIKAN\n",
      "Telkom University\n",
      "S1 Sains Data | IPK: 3.76 / 4.00\n",
      "Anggota Himpunan Mahasiswa Data Sains (HIMADS), 2023 - 2025 2023- 2025\n",
      "PE...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV_Dito Adistya Wirawan_extraction_result.json`\n",
      "\n",
      "--- Memproses file: CV_Faiz Ramadhan A.pdf ---\n",
      "üìå Ekstraksi teks dari CV_Faiz Ramadhan A.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "Faiz Ramadhan Alvi\n",
      "faizralvi@gmail.com | +62 812 8409 4673 | linkedin/in/faiz-ramadhan-alvi | Bekasi, Indonesia\n",
      "PROFILE\n",
      "undergraduate student at Telkom University‚Äôs Faculty of Informatics, majoring in Data Science.\n",
      "Passionate about leveraging data to drive actionable insights, I have honed my expertise through\n",
      "hands-on projects, active participation in data science competitions, and leadership roles in academic\n",
      "and organizational settings. Currently, I serve as a Data Research Mentor at Central ...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV_Faiz Ramadhan A_extraction_result.json`\n",
      "\n",
      "--- Memproses file: CV_HAFIZH PUTRA ARDHANA .pdf ---\n",
      "üìå Ekstraksi teks dari CV_HAFIZH PUTRA ARDHANA .pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "Hafizh Putra Ardhana\n",
      "Bandung, West Java, 40288 | +62-812-6119-9448\n",
      "Linkedin : https://www.linkedin.com/in/hafizh-putra-ardhana-06887627a/\n",
      "Github : https://github.com/hafizhArdhana\n",
      "Email : hafizhardhana1@gmail.com\n",
      "About Me\n",
      "6th-semester undergraduate student majoring in Data Science at Telkom University with a GPA of\n",
      "3.83. Possessing a strong background in data analysis, programming, and mathematics. Actively\n",
      "engaged in organizations and various projects, I am committed to developing both hard and...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV_HAFIZH PUTRA ARDHANA _extraction_result.json`\n",
      "\n",
      "--- Memproses file: CV_Muhammad_Rafan_Pradipta.pdf ---\n",
      "üìå Ekstraksi teks dari CV_Muhammad_Rafan_Pradipta.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "Muhammad Rafan Pradipta\n",
      "+62 877 9805-4473 ‚àô rafan007@gmail.com | rafanpradipta@student.telkomuniversity.ac.id ‚àô Bandung\n",
      "Summary\n",
      "Data Science student at Telkom University (GPA 3.72) specializing in machine learning, predictive\n",
      "modeling, and database management. Finalist in the 2023 Gammafest Big Data Competition. Data\n",
      "Analyst Intern at Ramir Consulting with hands-on experience in business intelligence and real-world data\n",
      "analysis. Proficient in Python, MySQL, and Java, passionate about solving co...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV_Muhammad_Rafan_Pradipta_extraction_result.json`\n",
      "\n",
      "--- Memproses file: CV_Wanda Azizah.pdf ---\n",
      "üìå Ekstraksi teks dari CV_Wanda Azizah.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "WANDA AZIZAH\n",
      "wandaaziza26@gmail.com | +6289519620950 | linkedin.com/in/wanda-azizah-36bbb2282/\n",
      "RIWAYAT PENDIDIKAN\n",
      "Universitas Telkom September 2022 - Sekarang\n",
      "S1 Data Sains | IPK: 3.89/4.00\n",
      "MAN 3 Jakarta\n",
      "2018-2021\n",
      "MIPA\n",
      "PENGALAMAN ORGANISASI\n",
      "Anggota Divisi Data Research, UKM CCI Februari 2023 - Oktober 2023\n",
      "Memperoleh pemahaman tentang data science dan analisis data menggunakan Python.\n",
      "Mengikuti pelatihan dan workshop untuk meningkatkan keterampilan dalam pengolahan data\n",
      "dan analisis statistik.\n",
      "P...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\CV_Wanda Azizah_extraction_result.json`\n",
      "\n",
      "--- Memproses file: EkmalCV.pdf ---\n",
      "üìå Ekstraksi teks dari EkmalCV.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "Ekmal Reyhan Tarihoran\n",
      "Jakarta | ekmalreyhan@gmail.com\n",
      "github.com/EkmalRey | linkedin.com/in/ekmalrey/\n",
      "Objective\n",
      "Motivated Data Science student with expertise in data analysis, machine learning, and market\n",
      "research, seeking to contribute to impactful projects through data-driven insights and innovative\n",
      "product development as a 2025 intern.\n",
      "EDUCATION\n",
      "Bachelor of Data Science Sep 2022 - Jun 2026 (Expected)\n",
      "Telkom University, Bandung GPA: 3.80/4.00\n",
      "RELEVANT EXPERIENCE\n",
      "Research Assistant Jan 2024 - ...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\EkmalCV_extraction_result.json`\n",
      "\n",
      "--- Memproses file: Farrell Habibie_Machine Learning_CV.pdf ---\n",
      "üìå Ekstraksi teks dari Farrell Habibie_Machine Learning_CV.pdf...\n",
      "Preview Teks (500 karakter pertama):\n",
      "Farrell Habibie Putra Haris (cid:131) +62-87866994648\n",
      "Undergrauate Data Science # farrellhrs@gmail.com\n",
      "School of Computing, Telkom University ¬ß Farrellhrs\n",
      "(cid:239) Farrell Habibie\n",
      "Education\n",
      "‚Ä¢Undergraduate Data Science at Telkom University School of Computing 2022-2026\n",
      "Telkom University, Bandung GPA: 3.82\n",
      "Projects\n",
      "‚Ä¢Indonesian Tweets Topic Classification May - Jun 2024\n",
      "Developed a Tweet Topic Classification model using a pre-trained BERT on Indonesian Tweets\n",
      "‚Äì Use NLP Preprocessing techniques to ...\n",
      "üöÄ Mengirim teks ke model untuk ekstraksi NER...\n",
      "‚è≥ Calling Generative Model...\n",
      "‚úÖ Found potential JSON block. Attempting to parse...\n",
      "‚úÖ Ekstraksi selesai! Hasil disimpan di `D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\extracted_cv_data\\Farrell Habibie_Machine Learning_CV_extraction_result.json`\n",
      "\n",
      "=== Selesai Memproses Semua File Yang Ada ===\n"
     ]
    }
   ],
   "source": [
    "cv_extraction_prompt = \"\"\"\n",
    "    Ekstrak semua informasi penting dari CV di bawah ini dan ubah ke dalam format JSON standar berikut. Hasilkan hanya JSON valid yang dimulai dengan ```json dan diakhiri dengan ```. Jangan tambahkan teks lain di luar blok JSON.\n",
    "\n",
    "    Jika ada bagian yang tidak tersedia, cukup gunakan string kosong atau array kosong.\n",
    "\n",
    "    Format standar:\n",
    "    dari sini kurung kurawal akan ditandai dengan 'kurwal()'\n",
    "    ```json\n",
    "      kurwal(\n",
    "        \"name\": \"\",\n",
    "        \"email\": \"\",\n",
    "        \"phone\": \"\",\n",
    "        \"linkedin\": \"\",\n",
    "        \"location\": \"\",\n",
    "        \"education\": [\n",
    "          kurwal(\n",
    "            \"institution\": \"\",\n",
    "            \"degree\": \"\",\n",
    "            \"major\": \"\",\n",
    "            \"start_date\": \"\",\n",
    "            \"end_date\": \"\",\n",
    "            \"gpa\": \"\"\n",
    "          )\n",
    "        ],\n",
    "        \"experience\": [\n",
    "          kurwal(\n",
    "            \"organization\": \"\",\n",
    "            \"role\": \"\",\n",
    "            \"start_date\": \"\",\n",
    "            \"end_date\": \"\",\n",
    "            \"description\": \"\"\n",
    "          kurwal)\n",
    "        ],\n",
    "        \"awards\": [\n",
    "          kurwal(\n",
    "            \"name\": \"\",\n",
    "            \"start_date\": \"\",\n",
    "            \"end_date\": \"\",\n",
    "            \"description\": \"\"\n",
    "          kurwal)\n",
    "        ],\n",
    "        \"certifications\": [\n",
    "          kurwal(\n",
    "            \"name\": \"\",\n",
    "            \"start_date\": \"\",\n",
    "            \"end_date\": \"\",\n",
    "            \"modules\": [\"\"]\n",
    "          kurwal)\n",
    "        ],\n",
    "        \"skills\": kurwal(\n",
    "          \"languages\": [\"\"],\n",
    "          \"software\": [\"\"],\n",
    "          \"other\": [\"\"]\n",
    "        kurwal)\n",
    "      kurwal)```\n",
    "    Ini CV-nya: {text}\n",
    "\n",
    "        ---\n",
    "\n",
    "    Instruksi:\n",
    "\n",
    "     Jika ada bagian yang kosong (misalnya, awards atau certifications tidak ada), cukup hilangkan bagian tersebut dari JSON yang dihasilkan.\n",
    "\n",
    "    Jika ada informasi yang tidak lengkap (misalnya, ada bagian education yang tidak memiliki gpa), tetap masukkan bagian tersebut dengan nilai kosong untuk yang hilang.\n",
    "\n",
    "    Untuk pendidikan (misal \"Bachelor of Science\" vs \"Sarjana Sains\")\n",
    "\n",
    "    Untuk skills (misal \"Python\" vs \"python programming\" vs \"Programming in Python\")\n",
    "\n",
    "    Untuk roles/experience yang beda cara nulis tapi sama arti (\"Software Engineer\" vs \"Engineer, Software Development\")\n",
    "\n",
    "    Translate semua ke bahasa inggris ya\n",
    "    \"\"\"\n",
    "\n",
    "# Batas maksimal file yang akan diproses \n",
    "MAX_FILES_TO_PROCESS = 10 # 5 dulu biar ga terlalu berat\n",
    "\n",
    "# --- Bagian ini otomatis membaca file dari folder ---\n",
    "file_paths_to_process = []\n",
    "if not os.path.isdir(input_folder_path):\n",
    "    print(f\"‚ùå Error: Folder input tidak ditemukan atau bukan direktori: {input_folder_path}\")\n",
    "else:\n",
    "    print(f\"üîé Mencari file PDF dan DOCX di folder: {input_folder_path}\")\n",
    "    # Loop melalui setiap item di dalam folder\n",
    "    for item_name in os.listdir(input_folder_path):\n",
    "        item_path = os.path.join(input_folder_path, item_name) # Gabungkan path folder dengan nama item\n",
    "        # Cek apakah itu file (bukan sub-folder) dan punya ekstensi .pdf atau .docx\n",
    "        if os.path.isfile(item_path) and item_name.lower().endswith(('.pdf', '.docx')):\n",
    "            file_paths_to_process.append(item_path) # Tambahkan ke daftar proses\n",
    "\n",
    "    print(f\"‚úÖ Ditemukan {len(file_paths_to_process)} file PDF/DOCX.\")\n",
    "\n",
    "# Terapkan batas maksimal file jika jumlahnya melebihi\n",
    "if len(file_paths_to_process) > MAX_FILES_TO_PROCESS:\n",
    "    print(f\"‚ö†Ô∏è Jumlah file ({len(file_paths_to_process)}) melebihi batas ({MAX_FILES_TO_PROCESS}). Hanya memproses {MAX_FILES_TO_PROCESS} file pertama.\")\n",
    "    file_paths_to_process = file_paths_to_process[:MAX_FILES_TO_PROCESS] # Potong daftar jika melebihi batas\n",
    "\n",
    "print(f\"üìÇ Akan memproses {len(file_paths_to_process)} file...\")\n",
    "print(f\"üíæ Hasil akan disimpan di folder: {os.path.abspath(output_directory)}\") # Tampilkan path absolut folder output\n",
    "\n",
    "# Loop utama untuk memproses setiap file\n",
    "for file_path in file_paths_to_process:\n",
    "    print(f\"\\n--- Memproses file: {os.path.basename(file_path)} ---\") # Tampilkan nama file aja\n",
    "\n",
    "    # Cek apakah file ada (redundant setelah os.path.isfile, tapi jaga-jaga)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå File tidak ditemukan: {file_path}. Melewati file ini.\")\n",
    "        continue # Skip ke file berikutnya\n",
    "\n",
    "    # Ekstraksi teks dari file\n",
    "    print(f\"üìå Ekstraksi teks dari {os.path.basename(file_path)}...\")\n",
    "    extracted_text = extract_text(file_path)\n",
    "\n",
    "    # Tampilkan preview teks (opsional, bisa dikomen kalau teksnya sensitif)\n",
    "    print(\"Preview Teks (500 karakter pertama):\")\n",
    "    print(extracted_text[:500] + ('...' if len(extracted_text) > 500 else ''))\n",
    "\n",
    "    # Cek jika ekstraksi teks gagal atau menghasilkan teks kosong/error\n",
    "    if extracted_text.startswith(\"‚ùå Error\") or extracted_text.startswith(\"üìÑ (\"):\n",
    "        print(extracted_text) # Print pesan error atau warning\n",
    "        continue # Skip NER processing for this file\n",
    "\n",
    "    # Ekstraksi NER menggunakan model Gemini, passing prompt yang sudah didefinisikan di atas\n",
    "    print(f\"üöÄ Mengirim teks ke model untuk ekstraksi NER...\")\n",
    "    # Pastikan cv_extraction_prompt sudah diisi di bagian atas cell ini!\n",
    "    if not cv_extraction_prompt.strip():\n",
    "        print(\"‚ùå Error: Variabel 'cv_extraction_prompt' masih kosong!\")\n",
    "        # break \n",
    "        continue # Skip ke file berikutnya jika prompt kosong\n",
    "\n",
    "    ner_output = extract_ner_from_cv(extracted_text, cv_extraction_prompt) \n",
    "\n",
    "    # Tentukan nama file output JSON\n",
    "    base_filename = os.path.basename(file_path) # Ambil nama file aja (misal: CV_Jaka_Tingkir.pdf)\n",
    "    name_without_ext = os.path.splitext(base_filename)[0] # Hilangin ekstensinya (misal: CV_Jaka_Tingkir)\n",
    "    output_filename = f\"{name_without_ext}_extraction_result.json\"\n",
    "    full_output_path = os.path.join(output_directory, output_filename) # Gabungkan dengan folder output\n",
    "\n",
    "    # Simpan hasil ekstraksi (berupa dictionary Python) ke file JSON\n",
    "    try:\n",
    "        # json.dump akan mengubah dictionary jadi string JSON\n",
    "        with open(full_output_path, \"w\", encoding='utf-8') as f:\n",
    "             # indent=4 biar rapi, ensure_ascii=False biar karakter non-ASCII ga diubah jadi \\uXXXX\n",
    "            json.dump(ner_output, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"‚úÖ Ekstraksi selesai! Hasil disimpan di `{full_output_path}`\")\n",
    "    except Exception as e:\n",
    "         print(f\"‚ùå Error saat menyimpan hasil ke {full_output_path}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Selesai Memproses Semua File Yang Ada ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4b602",
   "metadata": {},
   "source": [
    "## **MEMASUKKAN DATABASE PEKERJAAN KE NEO4J**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6453c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GF 63\\AppData\\Local\\Temp\\ipykernel_14284\\662031351.py:37: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(insert_data, position, skills)\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import ast  # Untuk mengubah string ke list Python\n",
    "\n",
    "# Ganti sesuai dengan koneksi Neo4j kamu\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"test_12345\"\n",
    "\n",
    "# Inisialisasi koneksi ke Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#Load data\n",
    "data = pd.read_csv(job_csv_path, sep=';')\n",
    "\n",
    "# Pastikan kolom required_skills diparsing dengan benar\n",
    "data['required_skills'] = data['required_skills'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Fungsi untuk meng-insert data ke Neo4j\n",
    "def insert_data(tx, position, skills):\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (p:Position {name: $position})\n",
    "        WITH p\n",
    "        UNWIND $skills AS skill\n",
    "            MERGE (s:Skill {name: skill})\n",
    "            MERGE (p)-[:REQUIRES]->(s)\n",
    "    \"\"\", position=position, skills=skills)\n",
    "\n",
    "# Eksekusi untuk setiap baris di DataFrame\n",
    "with driver.session() as session:\n",
    "    for _, row in data.iterrows():\n",
    "        position = row['position_title']\n",
    "        skills = row['required_skills']\n",
    "        if skills:  # Pastikan list-nya tidak kosong\n",
    "            session.write_transaction(insert_data, position, skills)\n",
    "\n",
    "# Tutup koneksi ke Neo4j\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d99436-b0ea-4785-af98-0bebc6f33fa9",
   "metadata": {},
   "source": [
    "# Ekstraksi Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7375d-dbf3-4487-ba11-9df250f3e0b0",
   "metadata": {},
   "source": [
    "Memasukkan data JSON ke Neo4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa98d65-ffa4-4b4f-a3c3-51700813ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Koneksi ke Neo4j berhasil!\n",
      "üìÇ Membaca file JSON dari folder: extracted_cv_data\n",
      "\n",
      "--- Memproses file: CV Aqiela Putriana Shabira_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari CV Aqiela Putriana Shabira_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: CV_ Hanum Fadiannur_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari CV_ Hanum Fadiannur_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: CV_Dito Adistya Wirawan_extraction_result.json ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GF 63\\AppData\\Local\\Temp\\ipykernel_14284\\3453470794.py:245: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(insert_cv, cv_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Berhasil memasukkan data dari CV_Dito Adistya Wirawan_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: CV_Faiz Ramadhan A_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari CV_Faiz Ramadhan A_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: CV_HAFIZH PUTRA ARDHANA _extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari CV_HAFIZH PUTRA ARDHANA _extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: CV_Muhammad_Rafan_Pradipta_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari CV_Muhammad_Rafan_Pradipta_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: CV_Wanda Azizah_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari CV_Wanda Azizah_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: EkmalCV_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari EkmalCV_extraction_result.json ke Neo4j.\n",
      "\n",
      "--- Memproses file: Farrell Habibie_Machine Learning_CV_extraction_result.json ---\n",
      "‚úÖ Berhasil memasukkan data dari Farrell Habibie_Machine Learning_CV_extraction_result.json ke Neo4j.\n",
      "\n",
      "=== Selesai memproses 9 file JSON ===\n",
      "‚úÖ Koneksi Neo4j ditutup.\n"
     ]
    }
   ],
   "source": [
    "# --- Import Library ---\n",
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Konfigurasi Koneksi Neo4j ---\n",
    "# üìå GANTI detail koneksi ini sesuai setup Neo4j \n",
    "uri = \"bolt://localhost:7687\"  # Alamat server Neo4j (biasanya localhost:7687)\n",
    "username = \"neo4j\"            # Username database Neo4j \n",
    "password = \"test_12345\"        # Password database Neo4j\n",
    "\n",
    "# Buat driver koneksi ke Neo4j\n",
    "try:\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    # Cek koneksi awal \n",
    "    driver.verify_connectivity()\n",
    "    print(\"‚úÖ Koneksi ke Neo4j berhasil!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gagal koneksi ke Neo4j: {e}\")\n",
    "    # Keluar dari script kalau koneksi gagal\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Fungsi untuk Memasukkan Data Satu CV ke dalam Graph ---\n",
    "# Fungsi ini akan dijalankan di dalam transaction Neo4j\n",
    "def insert_cv(tx, cv_data):\n",
    "    \"\"\"\n",
    "    Memasukkan data CV dari dictionary Python (hasil parse JSON) ke dalam graph Neo4j.\n",
    "    Menggunakan MERGE untuk membuat/menemukan node dan relationship.\n",
    "    \"\"\"\n",
    "    # Pastikan data CV punya email, kalau nggak ada, skip\n",
    "    if not cv_data.get(\"email\"):\n",
    "        print(\"‚ö†Ô∏è Data CV tidak punya email, melewati data ini.\")\n",
    "        return\n",
    "\n",
    "    # --- 1. Node Person ---\n",
    "    # MERGE berdasarkan email (diasumsikan unik untuk setiap Person)\n",
    "    # SET properti lain (name, phone, linkedin)\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (p:Person {email: $email})\n",
    "        SET p.name = $name,\n",
    "            p.phone = $phone,\n",
    "            p.linkedin = $linkedin\n",
    "    \"\"\", email=cv_data[\"email\"],\n",
    "         name=cv_data.get(\"name\", \"\"),\n",
    "         phone=cv_data.get(\"phone\", \"\"),\n",
    "         linkedin=cv_data.get(\"linkedin\", \"\"))\n",
    "\n",
    "    # --- 2. Node Education dan Relationship HAS_EDUCATION ---\n",
    "    # Loop melalui daftar pendidikan\n",
    "    for edu in cv_data.get(\"education\", []):\n",
    "        # Ambil data, beri nilai default \"\" jika tidak ada\n",
    "        institution = edu.get(\"institution\", \"\")\n",
    "        degree = edu.get(\"degree\", \"\")\n",
    "        major = edu.get(\"major\", \"\")\n",
    "        start_date = edu.get(\"start_date\", \"\")\n",
    "        end_date = edu.get(\"end_date\", \"\")\n",
    "\n",
    "        # >>> PENTING: Ubah nilai None (dari JSON null) menjadi string kosong \"\"\n",
    "        #    Properti di MERGE clause TIDAK BOLEH null di Cypher.\n",
    "        institution = \"\" if institution is None else institution\n",
    "        degree = \"\" if degree is None else degree\n",
    "        major = \"\" if major is None else major\n",
    "        start_date = \"\" if start_date is None else start_date\n",
    "        end_date = \"\" if end_date is None else end_date\n",
    "        # <<< Akhir penanganan None\n",
    "\n",
    "        # MERGE node Education berdasarkan kombinasi properti\n",
    "        # MERGE relationship HAS_EDUCATION dari Person ke Education\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (e:Education {\n",
    "                institution: $institution,\n",
    "                degree: $degree,\n",
    "                major: $major,\n",
    "                start_date: $start_date,\n",
    "                end_date: $end_date\n",
    "            })\n",
    "            MERGE (p:Person {email: $email})\n",
    "            MERGE (p)-[:HAS_EDUCATION]->(e)\n",
    "        \"\"\", institution=institution, # Gunakan variabel yang sudah diclean dari None\n",
    "             degree=degree,         # Gunakan variabel yang sudah diclean dari None\n",
    "             major=major,           # Gunakan variabel yang sudah diclean dari None\n",
    "             start_date=start_date,   # Gunakan variabel yang sudah diclean dari None\n",
    "             end_date=end_date,       # Gunakan variabel yang sudah diclean dari None\n",
    "             email=cv_data[\"email\"])\n",
    "\n",
    "    # --- 3. Node Experience dan Relationship HAS_EXPERIENCE ---\n",
    "    # Loop melalui daftar pengalaman kerja\n",
    "    for exp in cv_data.get(\"experience\", []):\n",
    "        # Ambil data, beri nilai default \"\" jika tidak ada\n",
    "        organization = exp.get(\"organization\", \"\")\n",
    "        role = exp.get(\"role\", \"\")\n",
    "        start_date = exp.get(\"start_date\", \"\")\n",
    "        end_date = exp.get(\"end_date\", \"\")\n",
    "        description = exp.get(\"description\", \"\") \n",
    "\n",
    "        # >>> PENTING: Ubah nilai None menjadi string kosong \"\" untuk properti di MERGE clause\n",
    "        organization = \"\" if organization is None else organization\n",
    "        role = \"\" if role is None else role\n",
    "        start_date = \"\" if start_date is None else start_date\n",
    "        end_date = \"\" if end_date is None else end_date\n",
    "        description = \"\" if description is None else description # Tetap clean untuk SET/parameter\n",
    "\n",
    "        # MERGE node Experience berdasarkan kombinasi properti\n",
    "        # MERGE relationship HAS_EXPERIENCE dari Person ke Experience\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (x:Experience {\n",
    "                organization: $organization,\n",
    "                role: $role,\n",
    "                start_date: $start_date,\n",
    "                end_date: $end_date\n",
    "            })\n",
    "            SET x.description = $description\n",
    "            MERGE (p:Person {email: $email})\n",
    "            MERGE (p)-[:HAS_EXPERIENCE]->(x)\n",
    "        \"\"\", organization=organization, # Gunakan variabel yang sudah diclean\n",
    "             role=role,             # Gunakan variabel yang sudah diclean\n",
    "             start_date=start_date,   # Gunakan variabel yang sudah diclean\n",
    "             end_date=end_date,       # Gunakan variabel yang sudah diclean\n",
    "             description=description, # Gunakan variabel yang sudah diclean (untuk SET)\n",
    "             email=cv_data[\"email\"])\n",
    "\n",
    "\n",
    "    # --- 4. Node Award dan Relationship RECEIVED_AWARD ---\n",
    "    # Loop melalui daftar penghargaan\n",
    "    for award in cv_data.get(\"awards\", []):\n",
    "        # Ambil data, beri nilai default \"\" jika tidak ada\n",
    "        name = award.get(\"name\", \"\")\n",
    "        start_date = award.get(\"start_date\", \"\")\n",
    "        end_date = award.get(\"end_date\", \"\")\n",
    "        description = award.get(\"description\", \"\") # Ini yang bikin error sebelumnya\n",
    "\n",
    "        # >>> PENTING: Ubah nilai None menjadi string kosong \"\" untuk properti di MERGE clause Award\n",
    "        name = \"\" if name is None else name # Check juga nama\n",
    "        start_date = \"\" if start_date is None else start_date\n",
    "        end_date = \"\" if end_date is None else end_date\n",
    "        description = \"\" if description is None else description # <--- Ini solusinya buat error kemarin!\n",
    "        # <<< Akhir penanganan None\n",
    "\n",
    "        # MERGE node Award berdasarkan kombinasi properti (termasuk description)\n",
    "        # MERGE relationship RECEIVED_AWARD dari Person ke Award\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (a:Award {\n",
    "                name: $name,\n",
    "                start_date: $start_date,\n",
    "                end_date: $end_date,\n",
    "                description: $description\n",
    "            })\n",
    "            MERGE (p:Person {email: $email})\n",
    "            MERGE (p)-[:RECEIVED_AWARD]->(a)\n",
    "        \"\"\", name=name, # Gunakan variabel yang sudah diclean\n",
    "             start_date=start_date, # Gunakan variabel yang sudah diclean\n",
    "             end_date=end_date,   # Gunakan variabel yang sudah diclean\n",
    "             description=description, # Gunakan variabel yang sudah diclean\n",
    "             email=cv_data[\"email\"])\n",
    "\n",
    "    # --- 5. Node Certification dan Relationship HAS_CERTIFICATION ---\n",
    "    # Loop melalui daftar sertifikasi\n",
    "    for cert in cv_data.get(\"certifications\", []):\n",
    "        # Ambil data, beri nilai default \"\" jika tidak ada\n",
    "        name = cert.get(\"name\", \"\")\n",
    "        start_date = cert.get(\"start_date\", \"\") # Tidak di MERGE clause di sini\n",
    "        end_date = cert.get(\"end_date\", \"\")   # Tidak di MERGE clause di sini\n",
    "        date = cert.get(\"date\", \"\")         # Tidak di MERGE clause di sini\n",
    "\n",
    "        # >>> PENTING: Ubah nilai None menjadi string kosong \"\" untuk properti di MERGE clause Certification\n",
    "        name = \"\" if name is None else name # Check nama\n",
    "        # Properti lain tidak di MERGE clause Certification, jadi null tidak masalah untuk MERGE itu sendiri\n",
    "        # Tapi tetap baiknya di-check kalau mau SET properti start_date/end_date/date di node Certification\n",
    "        start_date = \"\" if start_date is None else start_date # Clean untuk SET/parameter\n",
    "        end_date = \"\" if end_date is None else end_date     # Clean untuk SET/parameter\n",
    "        date = \"\" if date is None else date                 # Clean untuk SET/parameter\n",
    "        # <<< Akhir penanganan None\n",
    "\n",
    "        # MERGE node Certification berdasarkan nama\n",
    "        # MERGE relationship HAS_CERTIFICATION dari Person ke Certification\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (c:Certification {\n",
    "                name: $name \n",
    "            })\n",
    "            SET c.start_date = $start_date,\n",
    "                c.end_date = $end_date,\n",
    "                c.date = $date\n",
    "            MERGE (p:Person {email: $email})\n",
    "            MERGE (p)-[:HAS_CERTIFICATION]->(c)\n",
    "        \"\"\", name=name, # Gunakan variabel yang sudah diclean\n",
    "             start_date=start_date, # Gunakan variabel yang sudah diclean (untuk SET)\n",
    "             end_date=end_date,   # Gunakan variabel yang sudah diclean (untuk SET)\n",
    "             date=date,           # Gunakan variabel yang sudah diclean (untuk SET)\n",
    "             email=cv_data[\"email\"])\n",
    "\n",
    "    # --- 6. Node Skill dan Relationship HAS_SKILL ---\n",
    "    # Loop melalui kategori skill (languages, software, other)\n",
    "    for category, skills_list in cv_data.get(\"skills\", {}).items():\n",
    "        # Pastikan skills_list adalah list sebelum diloop\n",
    "        if isinstance(skills_list, list):\n",
    "            # Loop melalui setiap skill di kategori ini\n",
    "            for skill in skills_list:\n",
    "                skill_name = skill # Nilai skill langsung nama skillnya\n",
    "\n",
    "                # >>> PENTING: Ubah nilai None menjadi string kosong \"\" untuk properti di MERGE clause Skill\n",
    "                skill_name = \"\" if skill_name is None else skill_name # Check nama skill\n",
    "                # <<< Akhir penanganan None\n",
    "\n",
    "                # Hanya MERGE jika skill_name tidak kosong string (MERGE {name: \"\"}) mungkin tidak diinginkan\n",
    "                if skill_name:\n",
    "                     # MERGE node Skill berdasarkan nama\n",
    "                     # MERGE relationship HAS_SKILL dari Person ke Skill dengan properti category\n",
    "                     tx.run(\"\"\"\n",
    "                         MERGE (s:Skill {name: $skill_name})\n",
    "                         MERGE (p:Person {email: $email})\n",
    "                         MERGE (p)-[:HAS_SKILL {category: $category}]->(s)\n",
    "                     \"\"\", skill_name=skill_name, # Gunakan variabel yang sudah diclean\n",
    "                          email=cv_data[\"email\"],\n",
    "                          category=category)\n",
    "        # else:\n",
    "            # print(f\"‚ö†Ô∏è Warning: Skills for category '{category}' is not a list: {skills_list}\") # Debugging kalau skills bukan list\n",
    "\n",
    "\n",
    "# --- Bagian Utama: Membaca File JSON dan Memasukkan ke Neo4j ---\n",
    "\n",
    "# Cek apakah folder path ada\n",
    "if not os.path.isdir(json_folder_path):\n",
    "    print(f\"‚ùå Error: Folder JSON tidak ditemukan atau bukan direktori: {json_folder_path}\")\n",
    "    print(\"Pastikan folder 'extracted_cv_data' ada di lokasi yang sama dengan script ini, atau ganti 'json_folder_path' ke path yang benar.\")\n",
    "else:\n",
    "    print(f\"üìÇ Membaca file JSON dari folder: {json_folder_path}\")\n",
    "    # Buka sesi Neo4j untuk menjalankan transaksi\n",
    "    with driver.session() as session:\n",
    "        # Loop melalui setiap file di dalam folder\n",
    "        file_count = 0\n",
    "        for filename in os.listdir(json_folder_path):\n",
    "            # Proses hanya file yang berakhiran .json\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(json_folder_path, filename)\n",
    "                print(f\"\\n--- Memproses file: {filename} ---\")\n",
    "\n",
    "                try:\n",
    "                    # Buka dan baca file JSON\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        cv_data = json.load(file)\n",
    "\n",
    "                    # Jalankan fungsi insert_cv di dalam transaksi tulis (write_transaction)\n",
    "                    # Ini memastikan semua query untuk satu CV berhasil atau tidak sama sekali\n",
    "                    session.write_transaction(insert_cv, cv_data)\n",
    "                    print(f\"‚úÖ Berhasil memasukkan data dari {filename} ke Neo4j.\")\n",
    "                    file_count += 1\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"‚ùå Error membaca file JSON {filename}. Pastikan formatnya valid.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error saat memproses file {filename} atau memasukkan data ke Neo4j: {e}\")\n",
    "                    # bisa tambahin logika error handling lebih lanjut di sini\n",
    "                    # Misalnya, log errornya ke file lain, atau mencoba lagi\n",
    "\n",
    "    print(f\"\\n=== Selesai memproses {file_count} file JSON ===\")\n",
    "\n",
    "# --- Tutup Koneksi Driver ---\n",
    "driver.close()\n",
    "print(\"‚úÖ Koneksi Neo4j ditutup.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d059314-71e7-466d-9615-4fdebd71fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Koneksi ke Neo4j berhasil!\n",
      "‚úÖ Model 'paraphrase-MiniLM-L6-v2' berhasil dimuat.\n",
      "‚úÖ Berhasil memuat 397 lowongan dari D:\\KULIAH\\SEMESTER 6\\PROYEK SAINS DATA (CAPSTONE PROJECT)\\capstoneToDeploy\\cvProcessing\\jobRequirement.csv.\n",
      "\n",
      "--- Memulai Proses Rekomendasi ---\n",
      "\n",
      "‚û°Ô∏è Memproses user: AQIELA PUTRIANA SHABIRA (aqielanara@student.telkomuniversity.ac.id)\n",
      "   User Skills: ['python', 'sql', 'vscode', 'mysql', 'google colab', 'jupyter notebook', 'figma', 'canva', 'microsoft office', 'google workspace', 'time management', 'effective communication and teamwork', 'creativity in data visualization', 'adaptability & problem-solving']\n",
      "   ‚úÖ Ditemukan 192 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: HANUM FADIANNUR (hanumfadiannur29@gmail.com)\n",
      "   User Skills: ['python', 'mysql', 'indonesia', 'english', 'golang', 'dart', 'java', 'c++', 'tableau', 'microsoft word', 'microsoft excel', 'microsoft powerpoint', 'laravel', 'teaching', 'public speaking', 'discipline', 'responsibility', 'leadership', 'communication', 'teamwork']\n",
      "   ‚úÖ Ditemukan 216 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: DITO ADISTYA WIRAWAN (ditoadistya@student.telkomuniversity.ac.id)\n",
      "   User Skills: ['python', 'sql', 'mysql', 'jupyter notebook', 'tableau', 'teamwork', 'r', 'r studio', 'tensorflow', 'opencv', 'streamlit', 'data analysis', 'machine learning', 'statistics', 'data processing', 'programming', 'problem-solving', 'time management']\n",
      "   ‚úÖ Ditemukan 116 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: Faiz Ramadhan Alvi (faizralvi@gmail.com)\n",
      "   User Skills: ['python', 'sql', 'english', 'tableau', 'public speaking', 'leadership', 'communication', 'teamwork', 'tensorflow', 'indonesian', 'matplotlib', 'seaborn', 'excel', 'pandas', 'scikit-learn', 'ms office', 'problem solving']\n",
      "   ‚úÖ Ditemukan 120 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: Hafizh Putra Ardhana (hafizhardhana1@gmail.com)\n",
      "   User Skills: ['python', 'sql', 'microsoft office', 'golang', 'c++', 'responsibility', 'teamwork', 'good communications skills', 'detail oriented', 'machine learning', 'deep learning', 'databases']\n",
      "   ‚úÖ Ditemukan 186 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: Muhammad Rafan Pradipta (rafan007@gmail.com)\n",
      "   User Skills: ['python', 'sql', 'mysql', 'java', 'c++', 'public speaking', 'communication', 'tensorflow', 'pandas', 'scikit-learn', 'machine learning', 'google cloud', 'numpy', 'data visualization', 'predictive modeling', 'erd', 'stored procedures', 'query optimization', 'problem-solving', 'critical thinking', 'team collaboration']\n",
      "   ‚úÖ Ditemukan 128 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: WANDA AZIZAH (wandaaziza26@gmail.com)\n",
      "   User Skills: ['google colab', 'excel', 'bahasa indonesia (active)', 'english (passive)', 'beekeper studio', 'visual studio code', 'notepad++', 'data analysis', 'python programming', 'presentation and communication']\n",
      "   ‚úÖ Ditemukan 53 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: Ekmal Reyhan Tarihoran (ekmalreyhan@gmail.com)\n",
      "   User Skills: ['c++', 'tensorflow', 'data analysis', 'machine learning', 'keras', 'yolov8', 'indobert', 'go', 'market research', 'deep learning', 'computer vision', 'nlp', 'genetic algorithms', 'web app development', 'data structures', 'image classification', 'optical character recognition (ocr)']\n",
      "   ‚úÖ Ditemukan 18 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "‚û°Ô∏è Memproses user: Farrell Habibie Putra Haris (farrellhrs@gmail.com)\n",
      "   User Skills: ['python', 'java', 'c++', 'tableau', 'communication', 'problem solving', 'go', 'looker studio', 'vscode', 'git', 'github', 'event management', 'self-learning', 'adaptability', 'people management', 'data science', 'business intelligence', 'ml engineer']\n",
      "   ‚úÖ Ditemukan 186 lowongan di atas threshold (0.5).\n",
      "   ‚û°Ô∏è Menyimpan 5 rekomendasi teratas.\n",
      "\n",
      "--- Proses Rekomendasi Selesai ---\n",
      "‚úÖ Koneksi Neo4j ditutup.\n",
      "\n",
      "=== REKOMENDASI TOP 5 PER USER ===\n",
      "\n",
      "üë§ User: AQIELA PUTRIANA SHABIRA (aqielanara@student.telkomuniversity.ac.id)\n",
      "  1. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.683\n",
      "  2. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.671\n",
      "  3. Lowongan: Strategy & Operations\n",
      "     Skor Kemiripan: 0.649\n",
      "  4. Lowongan: E-Commerce Strategist\n",
      "     Skor Kemiripan: 0.647\n",
      "  5. Lowongan: Software Engineer\n",
      "     Skor Kemiripan: 0.64\n",
      "\n",
      "üë§ User: HANUM FADIANNUR (hanumfadiannur29@gmail.com)\n",
      "  1. Lowongan: Office Manager\n",
      "     Skor Kemiripan: 0.716\n",
      "  2. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.705\n",
      "  3. Lowongan: Advisory Strategic Resource\n",
      "     Skor Kemiripan: 0.698\n",
      "  4. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.687\n",
      "  5. Lowongan: Teller\n",
      "     Skor Kemiripan: 0.685\n",
      "\n",
      "üë§ User: DITO ADISTYA WIRAWAN (ditoadistya@student.telkomuniversity.ac.id)\n",
      "  1. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.742\n",
      "  2. Lowongan: System Software Developer\n",
      "     Skor Kemiripan: 0.695\n",
      "  3. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.676\n",
      "  4. Lowongan: Data Analytics Manager\n",
      "     Skor Kemiripan: 0.667\n",
      "  5. Lowongan: Full Stack Software Engineer\n",
      "     Skor Kemiripan: 0.656\n",
      "\n",
      "üë§ User: Faiz Ramadhan Alvi (faizralvi@gmail.com)\n",
      "  1. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.653\n",
      "  2. Lowongan: Teller\n",
      "     Skor Kemiripan: 0.623\n",
      "  3. Lowongan: Sales Stylist\n",
      "     Skor Kemiripan: 0.621\n",
      "  4. Lowongan: Office Manager\n",
      "     Skor Kemiripan: 0.617\n",
      "  5. Lowongan: Data Science Manager\n",
      "     Skor Kemiripan: 0.615\n",
      "\n",
      "üë§ User: Hafizh Putra Ardhana (hafizhardhana1@gmail.com)\n",
      "  1. Lowongan: Software Engineer\n",
      "     Skor Kemiripan: 0.67\n",
      "  2. Lowongan: Data Science Manager\n",
      "     Skor Kemiripan: 0.661\n",
      "  3. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.66\n",
      "  4. Lowongan: Strategy & Operations\n",
      "     Skor Kemiripan: 0.643\n",
      "  5. Lowongan: Teller\n",
      "     Skor Kemiripan: 0.639\n",
      "\n",
      "üë§ User: Muhammad Rafan Pradipta (rafan007@gmail.com)\n",
      "  1. Lowongan: System Software Developer\n",
      "     Skor Kemiripan: 0.728\n",
      "  2. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.689\n",
      "  3. Lowongan: Software Engineer\n",
      "     Skor Kemiripan: 0.663\n",
      "  4. Lowongan: Full Stack Software Engineer\n",
      "     Skor Kemiripan: 0.662\n",
      "  5. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.662\n",
      "\n",
      "üë§ User: WANDA AZIZAH (wandaaziza26@gmail.com)\n",
      "  1. Lowongan: Editor\n",
      "     Skor Kemiripan: 0.606\n",
      "  2. Lowongan: Data Entry\n",
      "     Skor Kemiripan: 0.595\n",
      "  3. Lowongan: Financial Business Management\n",
      "     Skor Kemiripan: 0.589\n",
      "  4. Lowongan: Patient Services\n",
      "     Skor Kemiripan: 0.58\n",
      "  5. Lowongan: Data Entry Operator\n",
      "     Skor Kemiripan: 0.576\n",
      "\n",
      "üë§ User: Ekmal Reyhan Tarihoran (ekmalreyhan@gmail.com)\n",
      "  1. Lowongan: System Software Developer\n",
      "     Skor Kemiripan: 0.673\n",
      "  2. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.598\n",
      "  3. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.559\n",
      "  4. Lowongan: Digital Marketing\n",
      "     Skor Kemiripan: 0.553\n",
      "  5. Lowongan: UI Designer\n",
      "     Skor Kemiripan: 0.541\n",
      "\n",
      "üë§ User: Farrell Habibie Putra Haris (farrellhrs@gmail.com)\n",
      "  1. Lowongan: System Software Developer\n",
      "     Skor Kemiripan: 0.705\n",
      "  2. Lowongan: Data Analyst\n",
      "     Skor Kemiripan: 0.703\n",
      "  3. Lowongan: Vice President of Business Intelligence\n",
      "     Skor Kemiripan: 0.685\n",
      "  4. Lowongan: E-Commerce Strategist\n",
      "     Skor Kemiripan: 0.683\n",
      "  5. Lowongan: Business Analyst\n",
      "     Skor Kemiripan: 0.676\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi Koneksi Neo4j ---\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"test_12345\"\n",
    "\n",
    "# Buat driver koneksi ke Neo4j\n",
    "try:\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    driver.verify_connectivity()\n",
    "    print(\"‚úÖ Koneksi ke Neo4j berhasil!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gagal koneksi ke Neo4j: {e}\")\n",
    "    driver = None # Set driver jadi None kalau gagal koneksi\n",
    "\n",
    "# --- Load model semantic MiniLM ---\n",
    "try:\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    print(\"‚úÖ Model 'paraphrase-MiniLM-L6-v2' berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gagal memuat model SentenceTransformer: {e}\")\n",
    "    model = None # Set model jadi None kalau gagal muat\n",
    "\n",
    "job_data = {}\n",
    "if os.path.exists(job_csv_path):\n",
    "    try:\n",
    "        with open(job_csv_path, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.DictReader(file,delimiter=\";\")\n",
    "            for row in reader:\n",
    "                position = row.get(\"position_title\") # Gunakan .get() jaga-jaga\n",
    "                required_skills_str = row.get(\"required_skills\", \"[]\") # Default ke string list kosong\n",
    "\n",
    "                if not position:\n",
    "                    print(f\"‚ö†Ô∏è Baris dilewati: 'position_title' kosong di baris {reader.line_num}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Ubah string list ke list Python asli dan lowercase\n",
    "                    # Gunakan ast.literal_eval() untuk parsing string list yang aman\n",
    "                    skills = ast.literal_eval(required_skills_str)\n",
    "                    # Pastikan hasilnya list sebelum diloop\n",
    "                    if isinstance(skills, list):\n",
    "                        skills = [s.strip().lower() for s in skills if s and s.strip()] # Filter None/kosong\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Skills bukan list untuk '{position}', skipping skills: {required_skills_str}\")\n",
    "                        skills = []\n",
    "\n",
    "                except (ValueError, SyntaxError) as e:\n",
    "                    print(f\"‚ùå Error parsing skills string for '{position}': {e} -> '{required_skills_str}'\")\n",
    "                    skills = []\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error tidak terduga parsing skills untuk '{position}': {e}\")\n",
    "                    skills = []\n",
    "\n",
    "                # Simpan data lowongan, bisa tambahin properti lain kalau perlu\n",
    "                job_data[position] = {\n",
    "                    \"required_skills\": skills,\n",
    "                    # Tambahin properti lain dari CSV kalau mau ditampilin di rekomendasi\n",
    "                    # \"company\": row.get(\"company\", \"\"),\n",
    "                    # \"url\": row.get(\"url\", \"\")\n",
    "                }\n",
    "        print(f\"‚úÖ Berhasil memuat {len(job_data)} lowongan dari {job_csv_path}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File CSV job requirements tidak ditemukan di: {job_csv_path}\")\n",
    "        job_data = {} # Set job_data kosong kalau file tidak ada\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saat membaca file CSV job requirements: {e}\")\n",
    "        job_data = {} # Set job_data kosong kalau ada error lain\n",
    "else:\n",
    "     print(f\"‚ùå File CSV job requirements tidak ditemukan di: {job_csv_path}\")\n",
    "     job_data = {}\n",
    "\n",
    "\n",
    "# Fungsi ambil skill user dari Neo4j\n",
    "def get_user_skills(tx):\n",
    "    \"\"\"Mengambil nama dan skill dari semua Person di Neo4j.\"\"\"\n",
    "    # Mengambil email juga sebagai identifier unik\n",
    "    result = tx.run(\"\"\"\n",
    "        MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)\n",
    "        RETURN p.email AS email, p.name AS name, collect(s.name) AS skills\n",
    "    \"\"\")\n",
    "    return [record for record in result]\n",
    "\n",
    "# Fungsi semantic similarity\n",
    "def calculate_semantic_similarity(skill_list1, skill_list2):\n",
    "    \"\"\"Menghitung cosine similarity antara dua list skill menggunakan model semantik.\"\"\"\n",
    "    # Langsung return 0 kalau salah satu list kosong atau model tidak dimuat\n",
    "    if not skill_list1 or not skill_list2 or model is None:\n",
    "        return 0.0\n",
    "\n",
    "    # Gabungkan skill jadi satu string per list\n",
    "    text1 = ', '.join(skill_list1)\n",
    "    text2 = ', '.join(skill_list2)\n",
    "\n",
    "    # Encode teks menjadi vector embedding\n",
    "    try:\n",
    "        emb1 = model.encode(text1, convert_to_tensor=True)\n",
    "        emb2 = model.encode(text2, convert_to_tensor=True)\n",
    "        # Hitung cosine similarity\n",
    "        score = util.pytorch_cos_sim(emb1, emb2).item()\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error menghitung similarity: {e}\")\n",
    "        return 0.0 # Return 0 kalau ada error\n",
    "\n",
    "\n",
    "# --- Proses Rekomendasi (Ambil Top 5 per User) ---\n",
    "recommendations = defaultdict(list) # Dictionary untuk menyimpan rekomendasi per user\n",
    "MIN_SIMILARITY_THRESHOLD = 0.5 # Ambang batas skor kemiripan minimum\n",
    "TOP_N = 5 # Jumlah rekomendasi teratas per user\n",
    "\n",
    "if driver is not None and model is not None and job_data: # Hanya jalan kalau koneksi, model, dan data job siap\n",
    "    print(\"\\n--- Memulai Proses Rekomendasi ---\")\n",
    "    with driver.session() as session:\n",
    "        user_data = session.execute_read(get_user_skills) # Ambil data user dari Neo4j\n",
    "\n",
    "        if not user_data:\n",
    "            print(\"‚ö†Ô∏è Tidak ada data user (Person) dengan skill ditemukan di Neo4j.\")\n",
    "\n",
    "        for record in user_data:\n",
    "            user_email = record[\"email\"] # Gunakan email sebagai kunci unik\n",
    "            user_name = record.get(\"name\", user_email) # Gunakan nama, fallback ke email\n",
    "            user_skills = [s.strip().lower() for s in record.get(\"skills\", []) if s and s.strip()] # Clean user skills\n",
    "\n",
    "            # List sementara untuk menyimpan semua lowongan yang cocok (di atas threshold) untuk user ini\n",
    "            user_job_matches = []\n",
    "\n",
    "            print(f\"\\n‚û°Ô∏è Memproses user: {user_name} ({user_email})\")\n",
    "            print(f\"   User Skills: {user_skills}\")\n",
    "\n",
    "            if not user_skills:\n",
    "                 print(f\"   ‚ö†Ô∏è User {user_name} tidak punya skill, melewati rekomendasi.\")\n",
    "                 continue\n",
    "\n",
    "            # Loop melalui setiap lowongan yang dimuat dari CSV\n",
    "            for job_title, job_info in job_data.items():\n",
    "                 req_skills = job_info.get(\"required_skills\", [])\n",
    "\n",
    "                 if not req_skills:\n",
    "                      # print(f\"   ‚ö†Ô∏è Lowongan '{job_title}' tidak punya required_skills, melewati.\")\n",
    "                      continue # Lewati lowongan tanpa required_skills\n",
    "\n",
    "                 # Hitung skor kemiripan semantik\n",
    "                 sim_score = calculate_semantic_similarity(user_skills, req_skills)\n",
    "\n",
    "                 # Jika skor di atas ambang batas, simpan di list sementara\n",
    "                 if sim_score >= MIN_SIMILARITY_THRESHOLD:\n",
    "                     user_job_matches.append({\n",
    "                         \"position_title\": job_title,\n",
    "                         \"similarity_score\": sim_score,\n",
    "                         # Tambahin info lowongan lain kalau perlu\n",
    "                         # \"company\": job_info.get(\"company\", \"\")\n",
    "                     })\n",
    "                     # Optional: print detail perbandingan kalau mau debug\n",
    "                     # print(f\"   -> Compared with Job: {job_title}, Score: {round(sim_score, 3)}\")\n",
    "\n",
    "\n",
    "            # Urutkan lowongan yang cocok berdasarkan skor kemiripan (descending)\n",
    "            user_job_matches.sort(key=lambda x: x[\"similarity_score\"], reverse=True)\n",
    "\n",
    "            # Ambil TOP N rekomendasi teratas\n",
    "            top_n_recommendations = user_job_matches[:TOP_N]\n",
    "\n",
    "            # Simpan rekomendasi teratas untuk user ini\n",
    "            recommendations[user_email] = top_n_recommendations\n",
    "\n",
    "            print(f\"   ‚úÖ Ditemukan {len(user_job_matches)} lowongan di atas threshold ({MIN_SIMILARITY_THRESHOLD}).\")\n",
    "            print(f\"   ‚û°Ô∏è Menyimpan {len(top_n_recommendations)} rekomendasi teratas.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Proses Rekomendasi Selesai ---\")\n",
    "    driver.close() # Tutup koneksi setelah selesai\n",
    "    print(\"‚úÖ Koneksi Neo4j ditutup.\")\n",
    "\n",
    "    # --- Tampilkan Hasil Rekomendasi Top 5 per User ---\n",
    "    print(\"\\n=== REKOMENDASI TOP 5 PER USER ===\")\n",
    "    if recommendations:\n",
    "        for user_email, job_list in recommendations.items():\n",
    "            user_name = next((rec[\"name\"] for rec in user_data if rec[\"email\"] == user_email), user_email) # Cari nama user lagi\n",
    "            print(f\"\\nüë§ User: {user_name} ({user_email})\")\n",
    "            if job_list:\n",
    "                # Urutkan lagi (meskipun seharusnya sudah terurut) dan tampilkan\n",
    "                for i, job_rec in enumerate(job_list):\n",
    "                    print(f\"  {i+1}. Lowongan: {job_rec['position_title']}\")\n",
    "                    print(f\"     Skor Kemiripan: {round(job_rec['similarity_score'], 3)}\")\n",
    "                    # Tampilkan info lowongan lain kalau ada\n",
    "                    # print(f\"     Perusahaan: {job_rec.get('company', 'N/A')}\")\n",
    "                    # print(f\"     Link: {job_rec.get('url', 'N/A')}\")\n",
    "            else:\n",
    "                print(\"  Tidak ada rekomendasi lowongan yang cocok di atas threshold.\")\n",
    "    else:\n",
    "        print(\"Tidak ada rekomendasi yang dihasilkan.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Proses Rekomendasi Tidak Dapat Dimulai ---\")\n",
    "    print(\"Pastikan koneksi Neo4j, model semantik, dan data lowongan berhasil dimuat.\")\n",
    "    if driver is not None:\n",
    "         driver.close() # Tutup driver kalau sempat terbuka tapi proses tidak jalan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b1ecc-84ed-4df6-b629-794e7f44a3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GF 63\\AppData\\Local\\Temp\\ipykernel_14284\\2090163125.py:7: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(hapus_semua_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua data berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def hapus_semua_data(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.write_transaction(hapus_semua_data)\n",
    "\n",
    "print(\"Semua data berhasil dihapus.\")\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b44f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
